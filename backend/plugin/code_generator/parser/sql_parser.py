"""SQL Parser for extracting table metadata from CREATE TABLE statements."""

import re
from dataclasses import dataclass
from enum import Enum
from typing import Optional


class DatabaseDialect(str, Enum):
    """Database dialect enumeration."""

    MYSQL = 'mysql'
    POSTGRESQL = 'postgresql'


@dataclass
class ColumnInfo:
    """Column information extracted from SQL."""

    name: str
    type: str  # Raw SQL type (e.g., "VARCHAR", "INTEGER")
    length: Optional[int] = None
    nullable: bool = True
    default: Optional[str] = None
    comment: Optional[str] = None
    is_primary_key: bool = False
    is_auto_increment: bool = False


@dataclass
class TableInfo:
    """Table information extracted from SQL."""

    name: str
    comment: Optional[str] = None
    columns: list[ColumnInfo] = None
    dialect: DatabaseDialect = DatabaseDialect.POSTGRESQL

    def __post_init__(self):
        if self.columns is None:
            self.columns = []


class SQLParser:
    """Parser for CREATE TABLE statements."""

    # Regex patterns for parsing
    MYSQL_COMMENT_PATTERN = re.compile(r"COMMENT\s+'([^']*)'", re.IGNORECASE)
    PG_COMMENT_ON_TABLE = re.compile(
        r"COMMENT\s+ON\s+TABLE\s+[`\"]?(?:\w+\.)?[`\"]?[`\"]?(\w+)[`\"]?\s+IS\s+'([^']*)';?", re.IGNORECASE
    )
    # Pattern for PostgreSQL COMMENT ON COLUMN
    # Supports: schema.table.column, table.column formats with optional quotes and newlines
    PG_COMMENT_ON_COLUMN = re.compile(
        r"COMMENT\s+ON\s+COLUMN\s+"
        r"(?:[`\"]?\w+[`\"]?\s*\.\s*)?"  # Optional schema. with optional whitespace
        r"[`\"]?(\w+)[`\"]?\s*\.\s*"  # Table name (captured group 1)
        r"[`\"]?(\w+)[`\"]?\s+"  # Column name (captured group 2)
        r"IS\s+'([^']*)';?",  # Comment value (captured group 3)
        re.IGNORECASE
    )
    # Pattern to split multiple CREATE TABLE statements
    CREATE_TABLE_PATTERN = re.compile(
        r'(CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?[^;]+\([^;]+\)[^;]*;?)',
        re.IGNORECASE | re.DOTALL
    )

    def parse(self, sql: str) -> TableInfo:
        """
        Parse CREATE TABLE statement (returns first table only).

        :param sql: SQL CREATE TABLE statement
        :return: TableInfo object
        """
        tables = self.parse_all(sql)
        if not tables:
            raise ValueError('No CREATE TABLE statements found in SQL')
        return tables[0]

    def parse_all(self, sql: str) -> list[TableInfo]:
        """
        Parse all CREATE TABLE statements from SQL.

        :param sql: SQL containing one or more CREATE TABLE statements
        :return: List of TableInfo objects
        """
        # Detect dialect
        dialect = self._detect_dialect(sql)

        # Find all CREATE TABLE statements
        create_statements = self._split_create_tables(sql)
        
        tables = []
        for create_sql in create_statements:
            try:
                # Extract table name
                table_name = self._extract_table_name(create_sql)
                
                # Extract table comment (look in both CREATE statement and full SQL)
                table_comment = self._extract_table_comment(sql, table_name, dialect)
                
                # Parse column definitions
                columns = self._parse_columns(create_sql, table_name, dialect)
                
                # Extract PostgreSQL column comments from full SQL
                if dialect == DatabaseDialect.POSTGRESQL:
                    self._extract_pg_column_comments(sql, table_name, columns)
                
                tables.append(TableInfo(
                    name=table_name,
                    comment=table_comment,
                    columns=columns,
                    dialect=dialect
                ))
            except ValueError as e:
                # Skip invalid CREATE TABLE statements
                continue
        
        return tables

    def _split_create_tables(self, sql: str) -> list[str]:
        """
        Split SQL into individual CREATE TABLE statements.

        :param sql: SQL containing CREATE TABLE statements
        :return: List of CREATE TABLE statement strings
        """
        # Find all CREATE TABLE ... ) patterns
        statements = []
        
        # Split by CREATE TABLE keyword while preserving the keyword
        parts = re.split(r'(?=CREATE\s+TABLE\s)', sql, flags=re.IGNORECASE)
        
        for part in parts:
            part = part.strip()
            if not part or not re.match(r'CREATE\s+TABLE\s', part, re.IGNORECASE):
                continue
            
            # Find the end of the CREATE TABLE statement
            # Look for the closing parenthesis that matches the opening one
            paren_depth = 0
            in_create = False
            end_idx = 0
            
            for i, char in enumerate(part):
                if char == '(':
                    paren_depth += 1
                    in_create = True
                elif char == ')':
                    paren_depth -= 1
                    if in_create and paren_depth == 0:
                        # Found the closing parenthesis
                        # Include any trailing options (ENGINE, CHARSET, etc.)
                        end_idx = i + 1
                        # Look for semicolon or next statement
                        rest = part[end_idx:]
                        semicolon_match = re.search(r';', rest)
                        if semicolon_match:
                            end_idx += semicolon_match.end()
                        else:
                            # Include options until newline or end
                            options_match = re.match(r'[^;\n]*', rest)
                            if options_match:
                                end_idx += options_match.end()
                        break
            
            if end_idx > 0:
                statements.append(part[:end_idx].strip())
            elif in_create:
                # Fallback: use the whole part
                statements.append(part.strip())
        
        return statements

    def _extract_pg_column_comments(self, sql: str, table_name: str, columns: list[ColumnInfo]) -> None:
        """
        Extract PostgreSQL column comments and update column objects.

        :param sql: Full SQL content
        :param table_name: Table name
        :param columns: List of ColumnInfo objects to update
        """
        for match in self.PG_COMMENT_ON_COLUMN.finditer(sql):
            tbl_name, col_name, comment = match.groups()
            if tbl_name.lower() == table_name.lower():
                for column in columns:
                    if column.name.lower() == col_name.lower():
                        column.comment = comment
                        break

    def _detect_dialect(self, sql: str) -> DatabaseDialect:
        """
        Detect database dialect from SQL syntax.

        :param sql: SQL statement
        :return: DatabaseDialect
        """
        sql_upper = sql.upper()

        # MySQL indicators
        mysql_indicators = [
            'AUTO_INCREMENT',
            'ENGINE=',
            'CHARSET=',
            'COLLATE=',
            '`',  # Backticks
        ]

        # PostgreSQL indicators
        pg_indicators = [
            'SERIAL',
            'BIGSERIAL',
            'SMALLSERIAL',
            'COMMENT ON COLUMN',
            'COMMENT ON TABLE',
            '::',  # Type casting
        ]

        mysql_score = sum(1 for indicator in mysql_indicators if indicator in sql_upper)
        pg_score = sum(1 for indicator in pg_indicators if indicator in sql_upper)

        return DatabaseDialect.MYSQL if mysql_score > pg_score else DatabaseDialect.POSTGRESQL

    def _extract_table_name(self, sql: str) -> str:
        """
        Extract table name from CREATE TABLE statement.

        :param sql: SQL statement
        :return: Table name
        """
        # Match: CREATE TABLE [IF NOT EXISTS] ["schema".]"table_name" or schema.table_name
        # Handle quoted identifiers for PostgreSQL and MySQL
        # Use \s* to handle newlines between schema and table name
        pattern = re.compile(
            r'CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?'
            r'(?:'
            r'[`"]?(\w+)[`"]?\s*\.\s*[`"]?(\w+)[`"]?'  # schema.table format
            r'|'
            r'[`"]?(\w+)[`"]?'  # simple table name
            r')',
            re.IGNORECASE
        )
        match = pattern.search(sql)
        if not match:
            raise ValueError('Could not extract table name from SQL')
        
        # Groups: (schema, table_from_schema_format, table_only)
        schema, table_with_schema, table_only = match.groups()
        return table_with_schema or table_only

    def _extract_table_comment(self, sql: str, table_name: str, dialect: DatabaseDialect) -> Optional[str]:
        """
        Extract table comment.

        :param sql: SQL statement
        :param table_name: Table name
        :param dialect: Database dialect
        :return: Table comment or None
        """
        if dialect == DatabaseDialect.MYSQL:
            # MySQL: COMMENT='...' at end of CREATE TABLE
            pattern = re.compile(r"COMMENT\s*=\s*'([^']*)'", re.IGNORECASE)
            match = pattern.search(sql)
            return match.group(1) if match else None
        else:
            # PostgreSQL: COMMENT ON TABLE ... IS '...'
            match = self.PG_COMMENT_ON_TABLE.search(sql)
            if match and match.group(1).lower() == table_name.lower():
                return match.group(2)
            return None

    def _parse_columns(self, sql: str, table_name: str, dialect: DatabaseDialect) -> list[ColumnInfo]:
        """
        Parse column definitions from CREATE TABLE statement.

        :param sql: SQL statement
        :param table_name: Table name
        :param dialect: Database dialect
        :return: List of ColumnInfo objects
        """
        # Extract the column definitions section
        # Find content between first ( and last )
        start_idx = sql.find('(')
        end_idx = sql.rfind(')')
        if start_idx == -1 or end_idx == -1:
            return []

        columns_section = sql[start_idx + 1 : end_idx]

        # Split by comma, but be careful with nested parentheses
        column_defs = self._split_column_definitions(columns_section)

        columns = []
        primary_keys = set()

        # First pass: identify primary keys from constraints
        for col_def in column_defs:
            col_def_stripped = col_def.strip()
            if col_def_stripped.upper().startswith('PRIMARY KEY'):
                # Extract column names from PRIMARY KEY (col1, col2, ...)
                pk_match = re.search(r'PRIMARY\s+KEY\s*\(([^)]+)\)', col_def_stripped, re.IGNORECASE)
                if pk_match:
                    pk_cols = [c.strip().strip('`"') for c in pk_match.group(1).split(',')]
                    primary_keys.update(pk_cols)

        # Second pass: parse column definitions
        for col_def in column_defs:
            col_def_stripped = col_def.strip()

            # Skip constraint definitions
            if any(
                col_def_stripped.upper().startswith(kw)
                for kw in ['PRIMARY KEY', 'FOREIGN KEY', 'UNIQUE', 'CHECK', 'CONSTRAINT', 'INDEX', 'KEY']
            ):
                continue

            # Parse column
            column = self._parse_column_definition(col_def_stripped, dialect)
            if column:
                # Check if this column is a primary key
                if column.name in primary_keys:
                    column.is_primary_key = True
                columns.append(column)

        return columns

    def _split_column_definitions(self, columns_section: str) -> list[str]:
        """
        Split column definitions by comma, handling nested parentheses.

        :param columns_section: Column definitions section
        :return: List of column definition strings
        """
        result = []
        current = []
        paren_depth = 0

        for char in columns_section:
            if char == '(':
                paren_depth += 1
                current.append(char)
            elif char == ')':
                paren_depth -= 1
                current.append(char)
            elif char == ',' and paren_depth == 0:
                result.append(''.join(current))
                current = []
            else:
                current.append(char)

        if current:
            result.append(''.join(current))

        return result

    def _parse_column_definition(self, col_def: str, dialect: DatabaseDialect) -> Optional[ColumnInfo]:
        """
        Parse a single column definition.

        :param col_def: Column definition string
        :param dialect: Database dialect
        :return: ColumnInfo object or None
        """
        # Remove leading/trailing whitespace
        col_def = col_def.strip()

        # Extract column name (first word, possibly quoted)
        name_match = re.match(r'^[`"]?(\w+)[`"]?\s+', col_def)
        if not name_match:
            return None

        column_name = name_match.group(1)
        remaining = col_def[name_match.end() :].strip()

        # Extract data type
        type_match = re.match(r'^(\w+)(?:\s*\(([^)]+)\))?', remaining, re.IGNORECASE)
        if not type_match:
            return None

        column_type = type_match.group(1).upper()
        type_params = type_match.group(2)
        remaining = remaining[type_match.end() :].strip()

        # Parse length/precision
        length = None
        if type_params:
            # Extract first number as length
            length_match = re.match(r'(\d+)', type_params)
            if length_match:
                length = int(length_match.group(1))

        # Initialize column info
        column = ColumnInfo(name=column_name, type=column_type, length=length)

        # Parse constraints and attributes
        remaining_upper = remaining.upper()

        # Check for PRIMARY KEY
        if 'PRIMARY KEY' in remaining_upper or column_type in ('SERIAL', 'BIGSERIAL', 'SMALLSERIAL'):
            column.is_primary_key = True
            column.nullable = False

        # Check for AUTO_INCREMENT
        if 'AUTO_INCREMENT' in remaining_upper or column_type in ('SERIAL', 'BIGSERIAL', 'SMALLSERIAL'):
            column.is_auto_increment = True

        # Check for NOT NULL
        if 'NOT NULL' in remaining_upper:
            column.nullable = False
        elif 'NULL' in remaining_upper and 'NOT NULL' not in remaining_upper:
            column.nullable = True

        # Extract DEFAULT value
        default_match = re.search(r'DEFAULT\s+([^\s,]+(?:\s+[^\s,]+)*?)(?:\s+(?:COMMENT|NOT|NULL|,|$))', remaining, re.IGNORECASE)
        if default_match:
            column.default = default_match.group(1).strip()

        # Extract MySQL inline comment
        if dialect == DatabaseDialect.MYSQL:
            comment_match = self.MYSQL_COMMENT_PATTERN.search(remaining)
            if comment_match:
                column.comment = comment_match.group(1)

        return column


# Singleton instance
sql_parser = SQLParser()
